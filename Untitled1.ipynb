{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fo8ZRJO3UiT",
        "colab_type": "code",
        "outputId": "31cda92c-bf9d-4ce3-fe89-cb7eca1a1671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "style-transfer.py - An implementation of the style transfer algorithm. It's a synthesis of the original paper, combined\n",
        "                    with the adaption to the loss function that adds in the variation loss factor for normalization.\n",
        "                    Components have been synthesized together.\n",
        "For reference:\n",
        "    - https://arxiv.org/pdf/1508.06576.pdf (original style loss paper)\n",
        "    - https://arxiv.org/pdf/1412.0035.pdf (explains the ideas behind variation loss)\n",
        "    - https://github.com/keras-team/keras/blob/master/examples/neural_style_transfer.py\n",
        "      (style transfer as given by the keras team)\n",
        "    - https://harishnarayanan.org/writing/artistic-style-transfer/ (longer tutorial that walks through convolutions)\n",
        "\"\"\"\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.applications import VGG16\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "\"\"\"parser = argparse.ArgumentParser(description='Image neural style transfer implemented with Keras')\n",
        "parser.add_argument('content_img', metavar='content', type=str, help='Path to target content image')\n",
        "parser.add_argument('style_img', metavar='style', type=str, help='Path to target style image')\n",
        "parser.add_argument('result_img_prefix', metavar='res_prefix', type=str, help='Name of generated image')\n",
        "parser.add_argument('--iter', type=int, default=10, required=False, help='Number of iterations to run')\n",
        "parser.add_argument('--content_weight', type=float, default=0.025, required=False, help='Content weight')\n",
        "parser.add_argument('--style_weight', type=float, default=1.0, required=False, help='Style weight')\n",
        "parser.add_argument('--var_weight', type=float, default=1.0, required=False, help='Total Variation weight')\n",
        "parser.add_argument('--height', type=int, default=512, required=False, help='Height of the images')\n",
        "parser.add_argument('--width', type=int, default=512, required=False, help='Width of the images')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Params #\n",
        "\"\"\"\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "img_size = img_height * img_width\n",
        "img_channels = 3\n",
        "\n",
        "content_path = \"/content/drive/My Drive/Deep Learning/Neural-Style-Transfer/content.jpg\"\n",
        "style_path = \"/content/drive/My Drive/Deep Learning/Neural-Style-Transfer/style.jpg\"\n",
        "target_path = \"/content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated\"\n",
        "target_extension = '.png'\n",
        "\n",
        "CONTENT_IMAGE_POS = 0\n",
        "STYLE_IMAGE_POS = 1\n",
        "GENERATED_IMAGE_POS = 2\n",
        "\n",
        "# Params #\n",
        "\n",
        "\n",
        "def process_img(path):\n",
        "    \"\"\"\n",
        "    Function for processing images to the format we need\n",
        "    :param path: The path to the image\n",
        "    :return: The image as a data array, scaled and reflected\n",
        "    \"\"\"\n",
        "    # Open image and resize it\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((img_width, img_height))\n",
        "\n",
        "    # Convert image to data array\n",
        "\n",
        "    data = np.asarray(img, dtype='float32')\n",
        "    data = np.expand_dims(data, axis=0)\n",
        "    data = data[:, :, :, :3]\n",
        "\n",
        "    # Apply pre-process to match VGG16 we are using\n",
        "    data[:, :, :, 0] -= 103.939\n",
        "    data[:, :, :, 1] -= 116.779\n",
        "    data[:, :, :, 2] -= 123.68\n",
        "\n",
        "    # Flip from RGB to BGR\n",
        "    data = data[:, :, :, ::-1]\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_layers(content_matrix, style_matrix, generated_matrix):\n",
        "    \"\"\"\n",
        "    Returns the content and style layers we need for the transfer\n",
        "    :param content_matrix: The feature matrix of the content image\n",
        "    :param style_matrix:  The feature matrix of the style image\n",
        "    :param generated_matrix:  The feature matrix of the generated image\n",
        "    :return: A tuple of content layers and style layers\n",
        "    \"\"\"\n",
        "    # Prep the model for our new input sizes\n",
        "    input_tensor = K.concatenate([content_matrix, style_matrix, generated_matrix], axis=0)\n",
        "    model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "    # Convert layers to dictionary\n",
        "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "    # Pull the specific layers we want\n",
        "    c_layers = layers['block2_conv2']\n",
        "    s_layers = ['block1_conv2', 'block2_conv2', 'block5_conv3']\n",
        "    s_layers = [layers[layer] for layer in s_layers]\n",
        "\n",
        "    return c_layers, s_layers\n",
        "\n",
        "\n",
        "def content_loss(content_features, generated_features):\n",
        "    \"\"\"\n",
        "    Computes the content loss\n",
        "    :param content_features: The features of the content image\n",
        "    :param generated_features: The features of the generated image\n",
        "    :return: The content loss\n",
        "    \"\"\"\n",
        "    return 0.5 * K.sum(K.square(generated_features - content_features))\n",
        "\n",
        "\n",
        "def gram_matrix(features):\n",
        "    \"\"\"\n",
        "    Calculates the gram matrix of the feature representation matrix\n",
        "    :param features: The feature matrix that is used to calculate the gram matrix\n",
        "    :return: The gram matrix\n",
        "    \"\"\"\n",
        "    return K.dot(features, K.transpose(features))\n",
        "\n",
        "\n",
        "def style_loss(style_matrix, generated_matrix):\n",
        "    \"\"\"\n",
        "    Computes the style loss of the transfer\n",
        "    :param style_matrix: The style representation from the target style image\n",
        "    :param generated_matrix: The style representation from the generated image\n",
        "    :return: The loss from the style content\n",
        "    \"\"\"\n",
        "    # Permute the matrix to calculate proper covariance\n",
        "    style_features = K.batch_flatten(K.permute_dimensions(style_matrix, (2, 0, 1)))\n",
        "    generated_features = K.batch_flatten(K.permute_dimensions(generated_matrix, (2, 0, 1)))\n",
        "\n",
        "    # Get the gram matrices\n",
        "    style_mat = gram_matrix(style_features)\n",
        "    generated_mat = gram_matrix(generated_features)\n",
        "\n",
        "    return K.sum(K.square(style_mat - generated_mat)) / (4.0 * (img_channels ** 2) * (img_size ** 2))\n",
        "\n",
        "\n",
        "def variation_loss(generated_matrix):\n",
        "    \"\"\"\n",
        "    Computes the variation loss metric (used for normalization)\n",
        "    :param generated_matrix: The generated matrix\n",
        "    :return: The variation loss term for normalization\n",
        "    \"\"\"\n",
        "    a = K.square(generated_matrix[:, :img_height-1, :img_width-1, :] - generated_matrix[:, 1:, :img_width-1, :])\n",
        "    b = K.square(generated_matrix[:, :img_height-1, :img_width-1, :] - generated_matrix[:, :img_height-1, 1:, :])\n",
        "\n",
        "    return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "\n",
        "def total_loss(c_layer, s_layers, generated):\n",
        "    \"\"\"\n",
        "    Computes the total loss of a given iteration\n",
        "    :param c_layer: The layer used to compute the content loss\n",
        "    :param s_layers: The layer(s) used to compute the style loss\n",
        "    :param generated: The generated image\n",
        "    :return: The total loss\n",
        "    \"\"\"\n",
        "\n",
        "    content_weight = 0.025\n",
        "    style_weight = 1.0\n",
        "    variation_weight = 1.0\n",
        "\n",
        "    # Content loss\n",
        "    content_features = c_layer[CONTENT_IMAGE_POS, :, :, :]\n",
        "    generated_features = c_layer[GENERATED_IMAGE_POS, :, :, :]\n",
        "    c_loss = content_loss(content_features, generated_features)\n",
        "\n",
        "    # Style loss\n",
        "    s_loss = None\n",
        "    for layer in s_layers:\n",
        "        style_features = layer[STYLE_IMAGE_POS, :, :, :]\n",
        "        generated_features = layer[GENERATED_IMAGE_POS, :, :, :]\n",
        "        if s_loss is None:\n",
        "            s_loss = style_loss(style_features, generated_features) * (style_weight / len(s_layers))\n",
        "        else:\n",
        "            s_loss += style_loss(style_features, generated_features) * (style_weight / len(s_layers))\n",
        "\n",
        "    # Variation loss (for regularization)\n",
        "    v_loss = variation_loss(generated)\n",
        "\n",
        "    return content_weight * c_loss + s_loss + variation_weight * v_loss\n",
        "\n",
        "\n",
        "def eval_loss_and_grads(generated):\n",
        "    \"\"\"\n",
        "    Computes the loss and gradients\n",
        "    :param generated: The generated image\n",
        "    :return: The loss and the gradients\n",
        "    \"\"\"\n",
        "    generated = generated.reshape((1, img_height, img_width, 3))\n",
        "    outs = f_outputs([generated])\n",
        "    loss_value = outs[0]\n",
        "    grad_values = outs[1].flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "\n",
        "def save_image(filename, generated):\n",
        "    \"\"\"\n",
        "    Saves the generated image\n",
        "    :param filename: The filename that the image is saved to\n",
        "    :param generated: The image that we want saved\n",
        "    :return: Nothing\n",
        "    \"\"\"\n",
        "    # Reshape image and flip from BGR to RGB\n",
        "    generated = generated.reshape((img_height, img_width, 3))\n",
        "    generated = generated[:, :, ::-1]\n",
        "\n",
        "    # Re-apply the mean shift\n",
        "    generated[:, :, 0] += 103.939\n",
        "    generated[:, :, 1] += 116.779\n",
        "    generated[:, :, 2] += 123.68\n",
        "\n",
        "    # Clip values to 0-255\n",
        "    generated = np.clip(generated, 0, 255).astype('uint8')\n",
        "\n",
        "    cv2.imwrite(filename, generated)\n",
        "\n",
        "\n",
        "class Evaluator(object):\n",
        "    \"\"\"\n",
        "    Evaluator class used to track gradients and loss values together\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Prepare the generated image\n",
        "    generated_img = np.random.uniform(0, 255, (1, img_height, img_width, 3)) - 128.\n",
        "\n",
        "    # Load the respective content and style images\n",
        "    content = process_img(content_path)\n",
        "    style = process_img(style_path)\n",
        "\n",
        "    # Prepare the variables for the flow graph\n",
        "    content_image = K.variable(content)\n",
        "    style_image = K.variable(style)\n",
        "    generated_image = K.placeholder((1, img_height, img_width, 3))\n",
        "    loss = K.variable(0.)\n",
        "\n",
        "    # Grab the layers needed to prepare the loss metric\n",
        "    content_layer, style_layers = get_layers(content_image, style_image, generated_image)\n",
        "\n",
        "    # Define loss and gradient\n",
        "    loss = total_loss(content_layer, style_layers, generated_image)\n",
        "    grads = K.gradients(loss, generated_image)\n",
        "\n",
        "    # Define the output\n",
        "    outputs = [loss]\n",
        "    outputs += grads\n",
        "    f_outputs = K.function([generated_image], outputs)\n",
        "\n",
        "    evaluator = Evaluator()\n",
        "    iterations = 30\n",
        "\n",
        "    name = '{}-{}{}'.format(target_path, 0, target_extension)\n",
        "    save_image(name, generated_img)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        print('Iteration:', i)\n",
        "        start_time = time.time()\n",
        "        generated_img, min_val, info = fmin_l_bfgs_b(evaluator.loss, generated_img.flatten(),\n",
        "                                                     fprime=evaluator.grads, maxfun=20)\n",
        "        print('Loss:', min_val)\n",
        "        end_time = time.time()\n",
        "        print('Iteration {} took {} seconds'.format(i, end_time - start_time))\n",
        "        name = '{}-{}{}'.format(target_path, i+1, target_extension)\n",
        "        save_image(name, generated_img)\n",
        "        print('Saved image to: {}'.format(name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n",
            "Iteration: 0\n",
            "Loss: 21482420000.0\n",
            "Iteration 0 took 9.639661312103271 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-1.png\n",
            "Iteration: 1\n",
            "Loss: 11876093000.0\n",
            "Iteration 1 took 1.2769849300384521 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-2.png\n",
            "Iteration: 2\n",
            "Loss: 12041825000.0\n",
            "Iteration 2 took 1.2688088417053223 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-3.png\n",
            "Iteration: 3\n",
            "Loss: 8886636000.0\n",
            "Iteration 3 took 1.3024635314941406 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-4.png\n",
            "Iteration: 4\n",
            "Loss: 9929936000.0\n",
            "Iteration 4 took 1.2662746906280518 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-5.png\n",
            "Iteration: 5\n",
            "Loss: 10170643000.0\n",
            "Iteration 5 took 1.3140628337860107 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-6.png\n",
            "Iteration: 6\n",
            "Loss: 8640102000.0\n",
            "Iteration 6 took 1.2908213138580322 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-7.png\n",
            "Iteration: 7\n",
            "Loss: 7753227300.0\n",
            "Iteration 7 took 1.2832632064819336 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-8.png\n",
            "Iteration: 8\n",
            "Loss: 10636496000.0\n",
            "Iteration 8 took 1.2526254653930664 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-9.png\n",
            "Iteration: 9\n",
            "Loss: 7011418600.0\n",
            "Iteration 9 took 1.2957372665405273 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-10.png\n",
            "Iteration: 10\n",
            "Loss: 6217317000.0\n",
            "Iteration 10 took 1.351423740386963 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-11.png\n",
            "Iteration: 11\n",
            "Loss: 7693717500.0\n",
            "Iteration 11 took 1.2426238059997559 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-12.png\n",
            "Iteration: 12\n",
            "Loss: 7836864000.0\n",
            "Iteration 12 took 1.2946040630340576 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-13.png\n",
            "Iteration: 13\n",
            "Loss: 6804979700.0\n",
            "Iteration 13 took 1.2430002689361572 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-14.png\n",
            "Iteration: 14\n",
            "Loss: 7324436500.0\n",
            "Iteration 14 took 1.3037569522857666 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-15.png\n",
            "Iteration: 15\n",
            "Loss: 7758793700.0\n",
            "Iteration 15 took 1.2503290176391602 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-16.png\n",
            "Iteration: 16\n",
            "Loss: 7139787000.0\n",
            "Iteration 16 took 1.2383763790130615 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-17.png\n",
            "Iteration: 17\n",
            "Loss: 6981505000.0\n",
            "Iteration 17 took 1.259777545928955 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-18.png\n",
            "Iteration: 18\n",
            "Loss: 7855614000.0\n",
            "Iteration 18 took 1.2346234321594238 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-19.png\n",
            "Iteration: 19\n",
            "Loss: 7593749500.0\n",
            "Iteration 19 took 1.2566018104553223 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-20.png\n",
            "Iteration: 20\n",
            "Loss: 7049761300.0\n",
            "Iteration 20 took 1.258410930633545 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-21.png\n",
            "Iteration: 21\n",
            "Loss: 7079645700.0\n",
            "Iteration 21 took 1.2674343585968018 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-22.png\n",
            "Iteration: 22\n",
            "Loss: 7028326400.0\n",
            "Iteration 22 took 1.2589738368988037 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-23.png\n",
            "Iteration: 23\n",
            "Loss: 7218598400.0\n",
            "Iteration 23 took 1.2638027667999268 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-24.png\n",
            "Iteration: 24\n",
            "Loss: 7969967600.0\n",
            "Iteration 24 took 1.2516295909881592 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-25.png\n",
            "Iteration: 25\n",
            "Loss: 7101489000.0\n",
            "Iteration 25 took 1.2467188835144043 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-26.png\n",
            "Iteration: 26\n",
            "Loss: 8673457000.0\n",
            "Iteration 26 took 1.3049147129058838 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-27.png\n",
            "Iteration: 27\n",
            "Loss: 6150876000.0\n",
            "Iteration 27 took 1.278371810913086 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-28.png\n",
            "Iteration: 28\n",
            "Loss: 7192732700.0\n",
            "Iteration 28 took 1.2778489589691162 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-29.png\n",
            "Iteration: 29\n",
            "Loss: 7028798000.0\n",
            "Iteration 29 took 1.2708055973052979 seconds\n",
            "Saved image to: /content/drive/My Drive/Deep Learning/Neural-Style-Transfer/images/generated-30.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh7sxFwX5LzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}